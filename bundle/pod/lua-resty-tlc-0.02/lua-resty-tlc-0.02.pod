=encoding utf-8

#lua-resty-tlc

Two Layer Cache implementation using L<lua-resty-lrucache|https://github.com/openresty/lua-resty-lrucache> and L<shared dictionaries|https://github.com/openresty/lua-nginx-module#ngxshareddict>.

Cache entries are written to lru-cache in the current worker and to a shared dictionary.

Cache reads that miss in the worker's lru-cache instance are re-populated from the shared dictionary if available.

Values in shared dictionaries are automatically serialised and unserialised to JSON (custom serialisation functions are supported)

Also provides a manager module to maintain global set of TLC cache instances

#Overview


    lua_package_path "/path/to/lua-resty-tlc/lib/?.lua;;";
    
    lua_shared_dict tlc_cache 10m;
    lua_shared_dict tlc_cache2 1m;
    
    init_by_lua_block {
        local manager = require("resty.tlc.manager")
        manager.new("my_cache", {size = 500, dict = "tlc_cache"})
    
        manager.new("my_cache2", {size = 500, dict = "tlc_cache2"})
    }
    
    
    location = /get {
        content_by_lua_block {
            local manager = require("resty.tlc.manager")
            local cache = manager.get("my_cache")
    
            local args = ngx.req.get_uri_args()
            local key = args["key"]
    
            local data, err = cache:get(key)
            if err then
                ngx.log(ngx.ERR, err)
            elseif data == nil then
                ngx.status = ngx.HTTP_NOT_FOUND
                ngx.say("Not Found")
            else
                ngx.say(tostring(data))
            end
        }
    }
    
    location = /set {
        content_by_lua_block {
            local manager = require("resty.tlc.manager")
            local cache = manager.get("my_cache")
    
            local args = ngx.req.get_uri_args()
            local key = args["key"]
            local val = args["val"] or { foo = bar }
            local ttl = args["ttl"]
    
            local ok, err = cache:set(key, val, ttl)
            if not ok then
                ngx.log(ngx.ERR, err)
            end
        }
    }
    
    location = /flush {
        content_by_lua_block {
            local manager = require("resty.tlc.manager")
            local cache = manager.get("my_cache")
            cache:flush()
        }
    }
    
    location = /list {
        content_by_lua_block {
            local manager = require("resty.tlc.manager")
            local instances = manager.list()
    
            ngx.say(require("cjson").encode(instances))
        }
    }
    
    

#Methods


=over


=item *

L<manager>

=over


=item *

L<new>

=item *

L<get>

=item *

L<set>

=item *

L<delete>

=item *

L<list>

=back


=item *

L<cache>

=over


=item *

L<new>

=item *

L<set>

=item *

L<get>

=item *

L<delete>

=item *

L<flush>


=back


=back


=head2 manager



=head3 new

C<syntax: ok, err = manager.new(name, opts)>

Create a new C<resty.tlc.cache> instance with given name/id and options.

Will B<not> check if instance already exists, existing instances will be overwritten


=head3 get

C<syntax: cache = manager.get(name)>

Returns the specified TLC cache instance or nil


=head3 delete

C<syntax: manager.delete(name)>

Removes the specified cache instance.


=head3 list

C<syntax: instances = manager.list()>

Returns an array table of available cache instances


=head2 cache



=head3 new

C<syntax: instance = cache:new(opts)>

Creates a new instance of C<resty.tlc.cache>, C<opts> is a table of options for this instance.


    opts = {
        dict         = dict,         -- Shared dictionary name, required
        size         = size,         -- max_items parameter for LRU cache, optional, default 200
        pureffi      = pureffi,      -- Use the pureffi LRU cache variant, optional, default false
        loadfactor   = loadfactor,   -- Load factor for pureffi LRU cache, optional
        serialiser   = serialiser,   -- Function to serialise values when saving to shared dictionary, optional, defaults to pcall'd cjson encode
        unserialiser = unserialiser, -- Function to unserialise values when saving to shared dictionary, optional, defaults to pcall'd cjson decode
    }

Functions to serialise and unserialise should C<return nil, err> on failure.


=head3 set

C<syntax: ok, err = cache:set(key, value, ttl?)>

Set or update an entry in the cache.

C<ttl> is optional and in seconds


=head3 get

C<syntax: data = cache:get(key)>

Returns data from cache or C<nil> if not set


=head3 delete

C<syntax: cache:delete(key)>

Deletes entry from both LRU cache and shared dictionary

TODO: Delete from LRU cache in all workers


=head3 flush

C<syntax: cache:flush(hard?)>

Re-initialises LRU cache in current worker and flushes shared dictionary.

C<hard> argument will also call C<flush_expired()> on dictionary.

TODO: Re-initialise LRU cache in all workers


=head1 TODO



=over


=item *

Add feature to ngx_lua shared dictionary to retrieve remaining TTL of entry

=item *

Syncronise LRU cache delete / flush across workers


=back

